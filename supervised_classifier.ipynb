{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 15:27:40.618405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stuff.callbacks import all_callbacks\n",
    "from stuff import plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bkg = dataset.load_dataset(dataset='NuGun_preprocessed.h5', key='full_data_cyl')\n",
    "sig = dataset.load_dataset(dataset='BSM_preprocessed.h5', key='ttHto2B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate((bkg, sig))\n",
    "y = np.concatenate((np.zeros((len(bkg), 1)), np.ones((len(sig), 1))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12387750, 2)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jessicaprendi/opt/anaconda3/envs/SP/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "y = to_categorical(y)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(x, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_val = scaler.fit_transform(X_train_val)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 16:40:21.417036: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, input_shape=(99,), name='fc1', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu1'))\n",
    "model.add(Dense(32, name='fc2', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu2'))\n",
    "model.add(Dense(32, name='fc3', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='relu', name='relu3'))\n",
    "model.add(Dense(2, name='output', kernel_initializer='lecun_uniform', kernel_regularizer=l1(0.0001)))\n",
    "model.add(Activation(activation='softmax', name='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   1/7259 [..............................] - ETA: 3:36:42 - loss: 0.8093 - accuracy: 0.3486WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0041s vs `on_train_batch_end` time: 0.0055s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7251/7259 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9954\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.01639, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 0.01639, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 1: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 1: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 27s 3ms/step - loss: 0.0311 - accuracy: 0.9954 - val_loss: 0.0164 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "7247/7259 [============================>.] - ETA: 0s - loss: 0.0157 - accuracy: 0.9963\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 2: val_loss improved from 0.01639 to 0.01518, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 2: val_loss improved from 0.01639 to 0.01518, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 2: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 2: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0157 - accuracy: 0.9963 - val_loss: 0.0152 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "7256/7259 [============================>.] - ETA: 0s - loss: 0.0148 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 3: val_loss improved from 0.01518 to 0.01433, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 3: val_loss improved from 0.01518 to 0.01433, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 3: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 3: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0148 - accuracy: 0.9964 - val_loss: 0.0143 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "7252/7259 [============================>.] - ETA: 0s - loss: 0.0143 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 4: val_loss improved from 0.01433 to 0.01380, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 4: val_loss improved from 0.01433 to 0.01380, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 4: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 4: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 24s 3ms/step - loss: 0.0143 - accuracy: 0.9964 - val_loss: 0.0138 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "7248/7259 [============================>.] - ETA: 0s - loss: 0.0140 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 5: val_loss improved from 0.01380 to 0.01379, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 5: val_loss improved from 0.01380 to 0.01379, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 5: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 5: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 24s 3ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0138 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "7255/7259 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.01379\n",
      "\n",
      "Epoch 6: val_loss did not improve from 0.01379\n",
      "\n",
      "Epoch 6: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 6: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0138 - accuracy: 0.9965 - val_loss: 0.0139 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "7252/7259 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 7: val_loss improved from 0.01379 to 0.01344, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 7: val_loss improved from 0.01379 to 0.01344, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 7: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 7: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "7247/7259 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 8: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 8: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 25s 3ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0135 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "7243/7259 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 9: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 9: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 9: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0136 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "7258/7259 [============================>.] - ETA: 0s - loss: 0.0137 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 10: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 10: saving model to model_1/KERAS_check_model_epoch10.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0137 - accuracy: 0.9965 - val_loss: 0.0136 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "7243/7259 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 11: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 11: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "7255/7259 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.01344\n",
      "\n",
      "Epoch 12: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 12: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0136 - accuracy: 0.9964 - val_loss: 0.0135 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "7244/7259 [============================>.] - ETA: 0s - loss: 0.0136 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 13: val_loss improved from 0.01344 to 0.01339, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 13: val_loss improved from 0.01344 to 0.01339, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 13: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 13: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 24s 3ms/step - loss: 0.0136 - accuracy: 0.9965 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "7247/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 14: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 14: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0135 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 15/30\n",
      "7250/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 15: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 15: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 15: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0135 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 16/30\n",
      "7259/7259 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.01339\n",
      "\n",
      "Epoch 16: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 16: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0136 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 17/30\n",
      "7259/7259 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 17: val_loss improved from 0.01339 to 0.01326, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 17: val_loss improved from 0.01339 to 0.01326, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 17: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 17: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0133 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 18/30\n",
      "7248/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01326\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.01326\n",
      "\n",
      "Epoch 18: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 18: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 19/30\n",
      "7255/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 19: val_loss improved from 0.01326 to 0.01317, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 19: val_loss improved from 0.01326 to 0.01317, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 19: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 19: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0132 - val_accuracy: 0.9966 - lr: 0.0010\n",
      "Epoch 20/30\n",
      "7244/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 20: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 20: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 20: saving model to model_1/KERAS_check_model_epoch20.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9964 - val_loss: 0.0137 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 21/30\n",
      "7246/7259 [============================>.] - ETA: 0s - loss: 0.0135 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 21: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 21: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0135 - accuracy: 0.9965 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 22/30\n",
      "7243/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 22: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 22: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0133 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 23/30\n",
      "7257/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 23: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 23: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0132 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 24/30\n",
      "7255/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 24: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 24: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0133 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 25/30\n",
      "7248/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 25: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 25: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9965 - val_loss: 0.0133 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 26/30\n",
      "7251/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.01317\n",
      "\n",
      "Epoch 26: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 26: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0134 - val_accuracy: 0.9965 - lr: 0.0010\n",
      "Epoch 27/30\n",
      "7254/7259 [============================>.] - ETA: 0s - loss: 0.0134 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 27: val_loss improved from 0.01317 to 0.01315, saving model to model_1/KERAS_check_best_model.h5\n",
      "\n",
      "Epoch 27: val_loss improved from 0.01317 to 0.01315, saving model to model_1/KERAS_check_best_model_weights.h5\n",
      "\n",
      "Epoch 27: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 27: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0134 - accuracy: 0.9964 - val_loss: 0.0132 - val_accuracy: 0.9966 - lr: 0.0010\n",
      "Epoch 28/30\n",
      "7255/7259 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9964\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 28: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 28: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 24s 3ms/step - loss: 0.0133 - accuracy: 0.9964 - val_loss: 0.0133 - val_accuracy: 0.9964 - lr: 0.0010\n",
      "Epoch 29/30\n",
      "7254/7259 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 29: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 29: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 26s 4ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0145 - val_accuracy: 0.9961 - lr: 0.0010\n",
      "Epoch 30/30\n",
      "7249/7259 [============================>.] - ETA: 0s - loss: 0.0133 - accuracy: 0.9965\n",
      "***callbacks***\n",
      "saving losses to model_1/losses.log\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.01315\n",
      "\n",
      "Epoch 30: saving model to model_1/KERAS_check_model_last.h5\n",
      "\n",
      "Epoch 30: saving model to model_1/KERAS_check_model_last_weights.h5\n",
      "\n",
      "Epoch 30: saving model to model_1/KERAS_check_model_epoch30.h5\n",
      "\n",
      "***callbacks end***\n",
      "\n",
      "7259/7259 [==============================] - 23s 3ms/step - loss: 0.0133 - accuracy: 0.9965 - val_loss: 0.0132 - val_accuracy: 0.9965 - lr: 0.0010\n"
     ]
    }
   ],
   "source": [
    "train = True\n",
    "if train:\n",
    "    adam = Adam(lr=0.0001)\n",
    "    model.compile(optimizer=adam, loss=['categorical_crossentropy'], metrics=['accuracy'])\n",
    "    callbacks = all_callbacks(\n",
    "        stop_patience=1000,\n",
    "        lr_factor=0.5,\n",
    "        lr_patience=10,\n",
    "        lr_epsilon=0.000001,\n",
    "        lr_cooldown=2,\n",
    "        lr_minimum=0.0000001,\n",
    "        outputDir='model_1',\n",
    "    )\n",
    "    model.fit(\n",
    "        X_train_val,\n",
    "        y_train_val,\n",
    "        batch_size=1024,\n",
    "        epochs=30,\n",
    "        validation_split=0.25,\n",
    "        shuffle=True,\n",
    "        callbacks=callbacks.callbacks,\n",
    "    )\n",
    "else:\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    model = load_model('model_1/KERAS_check_best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77424/77424 [==============================] - 80s 1ms/step\n",
      "Accuracy: 0.9964925026740127\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_keras = model.predict(X_test)\n",
    "print(\"Accuracy: {}\".format(accuracy_score(np.argmax(y_test, axis=1), np.argmax(y_keras, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_ = plotting.makeRoc(y_test, y_keras, le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(y_keras, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels = np.concatenate((np.ones(len(score_1)), np.zeros(len(score_0))))\n",
    "#all = np.concatenate((score_1, score_0))\n",
    "FPR, TPR, _ = roc_curve(y_score=np.argmin(y_keras, axis=1), y_true=y_test[:,0])\n",
    "AUC = auc(FPR, TPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2477550, 2)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1e-06, 1.05)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(FPR, TPR)\n",
    "plt.semilogx()\n",
    "plt.semilogy()\n",
    "plt.xlim([10**-(6), 1.0])\n",
    "plt.ylim([10**-(6), 1.05])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9953035999321515"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
